{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the grid world problem using Q-learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "\n",
    "from gym.envs.toy_text import discrete\n",
    "from gym.envs.classic_control import rendering\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the Grid World Environment in OpenAI Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CELL_SIZE = 100\n",
    "MARGIN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords(row, col, loc=\"center\"):\n",
    "    xc = (col + 1.5) * CELL_SIZE\n",
    "    yc = (row + 1.5) * CELL_SIZE\n",
    "\n",
    "    if (loc == \"center\"):\n",
    "        return xc, yc\n",
    "    elif (loc == \"interior_corners\"):\n",
    "        half_size = CELL_SIZE//2 - MARGIN\n",
    "        xl, xr = xc - half_size, xc + half_size\n",
    "        yt, yb = xc - half_size, xc +half_size\n",
    "        return [(xl, yt), (xr, yt), (xr, yb), (xl, yb)]\n",
    "    elif (loc == \"interior_triangle\"):\n",
    "        x1, y1 = xc, yc + CELL_SIZE//3\n",
    "        x2, y2 = xc + CELL_SIZE//3, yc - CELL_SIZE//3\n",
    "        x3, y3 = xc - CELL_SIZE//3, yc - CELL_SIZE//3\n",
    "        return [(x1, y1), (x2, y2), (x3, y3)]\n",
    "\n",
    "\n",
    "def draw_object(coords_list):\n",
    "    if (len(coords_list) == 1): # -> circle\n",
    "        obj = rendering.make_circle(int(0.45*CELL_SIZE))\n",
    "        obj_transform = rendering.Transform()\n",
    "        obj.add_attr(obj_transform)\n",
    "        obj_transform.set_translation(*coords_list[0])\n",
    "        obj.set_color(0.2, 0.2, 0.2) # -> black\n",
    "    elif (len(coords_list) == 3): # -> triangle\n",
    "        obj = rendering.FilledPolygon(coords_list)\n",
    "        obj.set_color(0.9, 0.6, 0.2) # -> yellow\n",
    "    elif (len(coords_list) > 3): # -> polygon\n",
    "        obj = rendering.FilledPolygon(coords_list)\n",
    "        obj.set_color(0.4, 0.4, 0.8) # -> blue\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorldEnv(discrete.DiscreteEnv):\n",
    "    def __init__(self, num_rows=4, num_cols=6, delay=0.05):\n",
    "        self.num_rows = num_rows\n",
    "        self.num_cols = num_cols\n",
    "        \n",
    "        self.delay = delay\n",
    "\n",
    "        move_up = lambda row, col: (max(row-1, 0), col)\n",
    "        move_down = lambda row, col: (min(row+1, num_rows-1), col)\n",
    "        move_left = lambda row, col: (row, max(col-1, 0))\n",
    "        move_right = lambda row, col: (row, min(col+1, num_cols-1))\n",
    "\n",
    "        self.action_defs = {\n",
    "            0: move_up, 1: move_right,\n",
    "            2: move_down, 3: move_left\n",
    "        }\n",
    "\n",
    "        # Number of states/actions\n",
    "        nS = num_cols * num_rows\n",
    "        nA = len(self.action_defs)\n",
    "        self.grid2state_dict = {\n",
    "            (s // num_cols, s % num_cols): s for s in range(nS)\n",
    "        }\n",
    "        self.state2grid_dict = {\n",
    "            s: (s // num_cols, s%num_cols) for s in range(nS)\n",
    "        }\n",
    "\n",
    "        # Gold state\n",
    "        gold_cell = (num_rows // 2, num_cols -2)\n",
    "\n",
    "        # Trap states\n",
    "        trap_cells = [\n",
    "            ((gold_cell[0] + 1), gold_cell[1]),\n",
    "            (gold_cell[0], gold_cell[1]),\n",
    "            ((gold_cell[0]-1), gold_cell[1]),\n",
    "        ]\n",
    "\n",
    "        gold_state = self.grid2state_dict[gold_cell]\n",
    "        trap_state = [self.grid2state_dict[(r, c)]\n",
    "                      for (r, c) in trap_cells]\n",
    "        \n",
    "        self.terminal_states = [gold_state] + trap_state\n",
    "        print(self.terminal_states)\n",
    "\n",
    "        # Build the transition probability\n",
    "        P = defaultdict(dict)\n",
    "\n",
    "        for s in range(nS):\n",
    "            row, col =  self.state2grid_dict[s]\n",
    "            P[s] = defaultdict(list)\n",
    "\n",
    "            for a in range(nA):\n",
    "                action = self.action_defs[a]\n",
    "                next_s = self.grid2state_dict[action(row, col)]\n",
    "\n",
    "                # Terminal state\n",
    "                if (self.is_terminal(next_s)):\n",
    "                    r = (1.0 if next_s == self.terminal_states[0] else -1.0)\n",
    "                else:\n",
    "                    r = 0.0\n",
    "                \n",
    "                if ( self.is_terminal(s)):\n",
    "                    done = True\n",
    "                    next_s = s\n",
    "                else:\n",
    "                    done = False\n",
    "                \n",
    "                P[s][s] = [(1.0, next_s, r, done)]\n",
    "\n",
    "        # Initial State distribution\n",
    "        isd = np.zeros(nS)\n",
    "        isd[0] = 1.0\n",
    "\n",
    "        super(GridWorldEnv, self).__init__(nS, nA, P, isd)\n",
    "        \n",
    "        self.viewer = None\n",
    "        self._build_display(gold_cell, trap_cells)\n",
    "\n",
    "\n",
    "    def is_terminal(self, state):\n",
    "        return state in self.terminal_states\n",
    "\n",
    "\n",
    "    def _build_display(self, gold_cell, trap_cells):\n",
    "        screen_width = (self.num_cols + 2) * CELL_SIZE\n",
    "        screen_height = (self.num_rows + 2) * CELL_SIZE\n",
    "        self.viewer = rendering.Viewer(screen_width, screen_height)\n",
    "\n",
    "        all_objects = []\n",
    "\n",
    "        # List of border points' coordinates\n",
    "        bp_list = [\n",
    "            (CELL_SIZE - MARGIN, CELL_SIZE - MARGIN),\n",
    "            (screen_width - CELL_SIZE + MARGIN, CELL_SIZE - MARGIN),\n",
    "            (screen_width - CELL_SIZE + MARGIN, screen_height - CELL_SIZE + MARGIN),\n",
    "            (CELL_SIZE - MARGIN, screen_height - CELL_SIZE + MARGIN)\n",
    "        ]\n",
    "        border = rendering.PolyLine(bp_list, True)\n",
    "        border.set_linewidth(5)\n",
    "        all_objects.append(border)\n",
    "\n",
    "        # Vertical lines\n",
    "        for col in range(self.num_cols + 1):\n",
    "            x1, y1 = (col + 1) * CELL_SIZE, CELL_SIZE\n",
    "            x2, y2 = (col + 1) * CELL_SIZE, (self.num_rows + 1) * CELL_SIZE\n",
    "            line = rendering.PolyLine([(x1, y1), (x2, y2)], False)\n",
    "            all_objects.append(line)\n",
    "\n",
    "        # Horizontal line\n",
    "        for row in range(self.num_rows + 1):\n",
    "            x1, y1 = CELL_SIZE, (row + 1) * CELL_SIZE\n",
    "            x2, y2 = (self.num_cols + 1) * CELL_SIZE, (row + 1) * CELL_SIZE\n",
    "            line = rendering.PolyLine([(x1, y1), x2, y2], False)\n",
    "            all_objects.append(line)\n",
    "        \n",
    "        # Traps: --> circles\n",
    "        for cell in trap_cells:\n",
    "            trap_coords = get_coords(*cell, loc=\"center\")\n",
    "            all_objects.append(draw_object([trap_coords]))\n",
    "        \n",
    "        # Gold: --> triangle\n",
    "        gold_coords = get_coords(*gold_cell, loc=\"interior_triangle\")\n",
    "        all_objects.append(gold_coords)\n",
    "\n",
    "        # Agent --> square or robot\n",
    "        if (os.path.exists(\"robot-coordinates.pkl\") and CELL_SIZE == 100):\n",
    "            agent_coords = pickle.load(\n",
    "                open(\"robot-coordinates.pkl\", \"rb\")\n",
    "            )\n",
    "            starting_coords = get_coords(0, 0, loc=\"center\")\n",
    "            agent_coords += np.array(starting_coords)\n",
    "        else:\n",
    "            agent_coords = get_coords(0, 0, loc=\"interior_corners\")\n",
    "        \n",
    "        agent = draw_object(agent_coords)\n",
    "        self.agent_trans = rendering.Transform()\n",
    "        agent.add_attr(self.agent_trans)\n",
    "        all_objects.append(agent)\n",
    "\n",
    "        for obj in all_objects:\n",
    "            self.viewer.add_geom(obj)\n",
    "\n",
    "\n",
    "    def render(self, mode=\"human\", done=False):\n",
    "        if (done):\n",
    "            sleep_time = 1\n",
    "        else:\n",
    "            sleep_time = self.delay\n",
    "        x_coord = self.s % self.num_cols\n",
    "        y_coord = self.s // self.num_cols\n",
    "        x_coord = (x_coord + 0) * CELL_SIZE\n",
    "        y_coord = (y_coord + 0) * CELL_SIZE\n",
    "        self.agent_trans.set_translation(x_coord, y_coord)\n",
    "        rend = self.viewer.render(\n",
    "            return_rgb_array=(mode == \"rgb_array\")\n",
    "        )\n",
    "        time.sleep(sleep_time)\n",
    "        return rend\n",
    "    \n",
    "\n",
    "    def close(self):\n",
    "        if (self.viewer):\n",
    "            self.viewer.close()\n",
    "            self.viewer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(self, mode='human', done=False):\n",
    "        if done:\n",
    "            sleep_time = 1\n",
    "        else:\n",
    "            sleep_time = self.delay\n",
    "        x_coord = self.s % self.num_cols\n",
    "        y_coord = self.s // self.num_cols\n",
    "        x_coord = (x_coord + 0) * CELL_SIZE\n",
    "        y_coord = (y_coord + 0) * CELL_SIZE\n",
    "        self.agent_trans.set_translation(x_coord, y_coord)\n",
    "        rend = self.viewer.render(\n",
    "            return_rgb_array=(mode == 'rgb_array'))\n",
    "        time.sleep(sleep_time)\n",
    "        return rend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GridWorldEnv(5, 6)\n",
    "for i in range(1):\n",
    "    s = env.reset()\n",
    "    env.render(mode=\"human\", done=False)\n",
    "\n",
    "    while True:\n",
    "        action = np.random.choice(env.nA)\n",
    "        res = env.step(action)\n",
    "        print(f\"Action {env.s} {action} --> {res}\")\n",
    "        env.render(mode=\"human\", done=res[2])\n",
    "        if (res[2]):\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    env = GridWorldEnv(5, 6)\n",
    "    for i in range(1):\n",
    "        s = env.reset()\n",
    "        env.render(mode='human', done=False)\n",
    "\n",
    "        while True:\n",
    "            action = np.random.choice(env.nA)\n",
    "            res = env.step(action)\n",
    "            print('Action ', env.s, action, ' -> ', res)\n",
    "            env.render(mode='human', done=res[2])\n",
    "            if res[2]:\n",
    "                break\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, env, learning_rate=0.01, discount_factor=0.9,  epsilon_greedy=0.9, epsilon_min=0.1, epsilon_decay=0.95):\n",
    "        self.env = env\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = discount_factor\n",
    "        self.epsilon = epsilon_greedy\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "\n",
    "        # Define the q_table\n",
    "        self.q_table = defaultdict(lambda: np.zeros(self.env.nA))\n",
    "\n",
    "    \n",
    "    def choose_action(self, state):\n",
    "        if (np.random.uniform() < self.epsilon):\n",
    "            action = np.random.choice(self.env.nA)\n",
    "        else:\n",
    "            q_vals = self.q_table[state]\n",
    "            perm_actions = np.random.permutation(self.env.nA)\n",
    "            q_vals = [q_vals[a] for a in perm_actions]\n",
    "            perm_q_argmax = np.argmax(q_vals)\n",
    "            action = perm_actions[perm_q_argmax]\n",
    "        return action\n",
    "    \n",
    "\n",
    "    def _learn(self, transition):\n",
    "        s, a, r, next_s, done = transition\n",
    "        q_val = self.q_table[s][a]\n",
    "        if (done):\n",
    "            q_target = r\n",
    "        else:\n",
    "            q_target = r + self.gamma + np.max(self.q_table[next_s])\n",
    "        \n",
    "        # Update the q_table\n",
    "        self.q_table[s][a] +=  self.lr * (q_target - q_val)\n",
    "\n",
    "        # Adjust the epsilon\n",
    "        self._adjust_epsilon()\n",
    "\n",
    "    \n",
    "    def _adjust_epsilon(self):\n",
    "        if (self.epsilon > self.epsilon_min):\n",
    "            self.epsilon *= self.epsilon_decay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Q-Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "Transition = namedtuple(\n",
    "    'Transition', ('state', 'action', 'reward', 'next_state', 'done'))\n",
    "\n",
    "\n",
    "def run_qlearning(agent, env, num_episodes=50):\n",
    "    history = []\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        env.render(mode='human')\n",
    "        final_reward, n_moves = 0.0, 0\n",
    "        while True:\n",
    "            action = agent.choose_action(state)\n",
    "            next_s, reward, done, _ = env.step(action)\n",
    "            agent._learn(Transition(state, action, reward,\n",
    "                                    next_s, done))\n",
    "            env.render(mode='human', done=done)\n",
    "            state = next_s\n",
    "            n_moves += 1\n",
    "            if done:\n",
    "                break\n",
    "            final_reward = reward\n",
    "        history.append((n_moves, final_reward))\n",
    "        print(f'Episode {episode}: Reward {final_reward:.2} #Moves {n_moves}')\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def plot_learning_history(history):\n",
    "    fig = plt.figure(1, figsize=(14, 10))\n",
    "    ax = fig.add_subplot(2, 1, 1)\n",
    "    episodes = np.arange(len(history))\n",
    "    moves = np.array([h[0] for h in history])\n",
    "    plt.plot(episodes, moves, lw=4,\n",
    "             marker=\"o\", markersize=10)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    plt.xlabel('Episodes', size=20)\n",
    "    plt.ylabel('# moves', size=20)\n",
    "\n",
    "    ax = fig.add_subplot(2, 1, 2)\n",
    "    rewards = np.array([h[1] for h in history])\n",
    "    plt.step(episodes, rewards, lw=4)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    plt.xlabel('Episodes', size=20)\n",
    "    plt.ylabel('Final rewards', size=20)\n",
    "    plt.savefig('q-learning-history.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    env = GridWorldEnv(num_rows=5, num_cols=6)\n",
    "    agent = Agent(env)\n",
    "    history = run_qlearning(agent, env)\n",
    "    env.close()\n",
    "\n",
    "    plot_learning_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
